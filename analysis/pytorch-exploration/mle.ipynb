{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32443bbd-7815-4364-be87-574b40d1ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch.nn\n",
    "from scvi.distributions import NegativeBinomial\n",
    "from typing import Optional\n",
    "from anndata import AnnData\n",
    "import scvi\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi.data.fields import(\n",
    "    LayerField, \n",
    "    CategoricalObsField,\n",
    "    NumericalObsField,\n",
    "    CategoricalJointObsField,\n",
    "    NumericalJointObsField,\n",
    ")\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi.module.base import (\n",
    "    BaseModuleClass,\n",
    "    LossRecorder,\n",
    "    auto_move_data,\n",
    ")\n",
    "from scvi.model.base import BaseModelClass, UnsupervisedTrainingMixin\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21da2ff-7afa-4a49-bfa3-f58502dfbaa0",
   "metadata": {},
   "source": [
    "I will be randomly generating data for now - this data follows a ZINB distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127fd6f-0822-4272-9169-b7b5de3d0313",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d34bd84-9bff-4d53-a9f4-2e7cc5aee29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scvi_version', 'model_name', 'setup_args', 'field_registries', '_scvi_uuid'])\n"
     ]
    }
   ],
   "source": [
    "adata = scvi.data.synthetic_iid()\n",
    "\n",
    "anndata_fields = [\n",
    "    LayerField(registry_key=\"x\", layer=None, is_count_data=True),\n",
    "    CategoricalObsField(registry_key=\"batch\", obs_key=\"batch\"),\n",
    "]\n",
    "adata_manager = AnnDataManager(fields=anndata_fields)\n",
    "adata_manager.register_fields(adata)\n",
    "print(adata_manager.registry.keys()) # There is additionally a _scvi_uuid key which is used to uniquely identify AnnData objects for subsequent retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504d96e-2e08-4f07-af0b-47ed94c4976f",
   "metadata": {},
   "source": [
    "## Probabilistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ee4eb-5c17-4be3-96b7-e2833d1a8803",
   "metadata": {},
   "source": [
    "For now, I am exclusively interested in an inferential task. I'll build up a generative model later by making assumptions about the distribution of these parameters. But for now, I will assume no variation in cell state. The gene expression of a gene $g$ in a cell $n$, $x_{ng}$, is then:\n",
    "$$ x_{ng} \\sim \\textrm{NegativeBinomial} (l_n \\mu_g, \\theta_g)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb387c6-4fcb-4472-ae50-637b9f642d5a",
   "metadata": {},
   "source": [
    "Where $\\mu_g$ and $\\theta_g$ are positive parameters to be learned (the mean and dispersion parameters of the negative binomial distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565137a0-9d7d-492d-b383-628484546bb7",
   "metadata": {},
   "source": [
    "### Inference mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc23d1-c679-47e4-9e22-85be642d0e4d",
   "metadata": {},
   "source": [
    "We can use maximum likelihood estimation to perform inference over the parameters $\\Theta=\\{ \\mu_g, \\theta_g \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8b92f9-1989-48d7-bacf-b1f465c14720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_Module(BaseModuleClass):\n",
    "    \"\"\"\n",
    "    Basic negative binomial model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input\n",
    "        Number of input genes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # in the init, we create the parameters of our elementary stochastic computation unit.\n",
    "\n",
    "        # First, we setup the parameters of the generative model\n",
    "        self.log_mu = torch.nn.Parameter(torch.randn(n_input))\n",
    "        self.log_theta = torch.nn.Parameter(torch.randn(n_input))\n",
    "\n",
    "    def _get_generative_input(self, tensors, inference_outputs):\n",
    "        x = tensors[_CONSTANTS.X_KEY]\n",
    "        # here we extract the number of UMIs per cell as a known quantity\n",
    "        library = torch.sum(x, dim=1, keepdim=True)\n",
    "\n",
    "        input_dict = {\n",
    "            \"library\": library,\n",
    "        }\n",
    "        return input_dict\n",
    "\n",
    "    @auto_move_data\n",
    "    def generative(self, library):\n",
    "        \"\"\"Runs the generative model.\"\"\"\n",
    "\n",
    "        # get the mean parameter of the negative binomial\n",
    "        mu = library * torch.exp(self.log_mu)\n",
    "        # get the dispersion parameter\n",
    "        theta = torch.exp(self.log_theta)\n",
    "\n",
    "        return dict(\n",
    "            mu=mu, theta=theta\n",
    "        )\n",
    "\n",
    "    def loss(\n",
    "        self,\n",
    "        tensors,\n",
    "        generative_outputs,\n",
    "    ):\n",
    "\n",
    "        # here, we would like to form the log likelihood\n",
    "        # so we extract all the required information\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "        mu = generative_outputs[\"mu\"]\n",
    "        theta = generative_outputs[\"theta\"]\n",
    "\n",
    "        # log likelihood\n",
    "        # note that I'm using the scVI NB which offers this mu/ theta parametrization, compatible with the Poisson-Gamma \n",
    "        log_lik = NegativeBinomial(mu=mu, theta=theta).log_prob(x).sum(dim=-1)\n",
    "\n",
    "        nll = torch.mean(-log_lik)\n",
    "        return LossRecorder(loss=nll, reconstruction_loss=nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f1092-f9e4-44f4-83a4-d1ff9a22f032",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dfc1d19-9f71-4c35-bb32-30a7a419bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_Model(UnsupervisedTrainingMixin, BaseModelClass):\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super(NB_Model, self).__init__(adata)\n",
    "\n",
    "        self.module = NB_Module(\n",
    "            n_input=self.summary_stats[\"n_vars\"],\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        self._model_summary_string = (\"NB Model has been created\")\n",
    "        self.init_params_ = self._get_init_params(locals())\n",
    "\n",
    "    @classmethod\n",
    "    def setup_anndata(\n",
    "        cls,\n",
    "        adata: AnnData,\n",
    "        batch_key: Optional[str] = None,\n",
    "        layer: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ) -> Optional[AnnData]:\n",
    "        setup_method_args = cls._get_setup_method_args(**locals())\n",
    "        anndata_fields = [\n",
    "            LayerField(REGISTRY_KEYS.X_KEY, layer, is_count_data=True),\n",
    "            CategoricalObsField(REGISTRY_KEYS.BATCH_KEY, batch_key),\n",
    "            # Dummy fields required for VAE class.\n",
    "            CategoricalObsField(REGISTRY_KEYS.LABELS_KEY, None),\n",
    "            NumericalObsField(\n",
    "                REGISTRY_KEYS.SIZE_FACTOR_KEY, None, required=False\n",
    "            ),\n",
    "            CategoricalJointObsField(\n",
    "                REGISTRY_KEYS.CAT_COVS_KEY, None\n",
    "            ),\n",
    "            NumericalJointObsField(\n",
    "                REGISTRY_KEYS.CONT_COVS_KEY, None\n",
    "            ),\n",
    "        ]\n",
    "        adata_manager = AnnDataManager(\n",
    "            fields=anndata_fields, setup_method_args=setup_method_args\n",
    "        )\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        cls.register_manager(adata_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81bbbd43-eddd-42ee-b395-6aed74076323",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_Model.setup_anndata(adata, batch_key=\"batch\")\n",
    "my_model = NB_Model(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af64d8ff-0ce1-472b-9502-447e60c4b1d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'enable_checkpointing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/midway2/jpopp/.conda/envs/scvi-scanpy/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:69\u001b[0m, in \u001b[0;36mUnsupervisedTrainingMixin.train\u001b[0;34m(self, max_epochs, use_gpu, train_size, validation_size, batch_size, early_stopping, plan_kwargs, **trainer_kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m es \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m trainer_kwargs[es] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     67\u001b[0m     early_stopping \u001b[38;5;28;01mif\u001b[39;00m es \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m trainer_kwargs\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m trainer_kwargs[es]\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mTrainRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_splitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_splitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runner()\n",
      "File \u001b[0;32m/scratch/midway2/jpopp/.conda/envs/scvi-scanpy/lib/python3.9/site-packages/scvi/train/_trainrunner.py:66\u001b[0m, in \u001b[0;36mTrainRunner.__init__\u001b[0;34m(self, model, training_plan, data_splitter, max_epochs, use_gpu, **trainer_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpus \u001b[38;5;241m=\u001b[39m gpus\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/midway2/jpopp/.conda/envs/scvi-scanpy/lib/python3.9/site-packages/scvi/train/_trainer.py:139\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, gpus, benchmark, flush_logs_every_n_steps, check_val_every_n_epoch, max_epochs, default_root_dir, enable_checkpointing, num_sanity_val_steps, enable_model_summary, early_stopping, early_stopping_monitor, early_stopping_min_delta, early_stopping_patience, early_stopping_mode, enable_progress_bar, progress_bar_refresh_rate, simple_progress_bar, logger, log_every_n_steps, replace_sampler_ddp, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     logger \u001b[38;5;241m=\u001b[39m SimpleLogger()\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_val_every_n_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_val_every_n_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_root_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_sanity_val_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sanity_val_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_model_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_model_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplace_sampler_ddp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace_sampler_ddp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/midway2/jpopp/.conda/envs/scvi-scanpy/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/env_vars_connector.py:40\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'enable_checkpointing'"
     ]
    }
   ],
   "source": [
    "my_model.train(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01f05a-ac31-41d8-a5c9-26a241c4d7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-scanpy",
   "language": "python",
   "name": "scvi-scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
